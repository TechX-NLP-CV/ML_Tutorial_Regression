{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Machine Learning Tutorial: Regression</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. What is Regression?\n",
    "Regression analysis is the process to find the relationship between the ***dependent variable*** and the ***independent variable***.\n",
    "\n",
    "Generally, regression analysis is mainly used for 2 completely different purposes:\n",
    "\n",
    "1. ***Predict*** or ***estimate*** the future value/trend using the observed data. This is widely used in salary forecasting, price estimation, drug efficiency test and so on.\n",
    "\n",
    "2. ***Reveal the causal relationships*** between the dependent and the independt variable (How one variable could influence the other).\n",
    "\n",
    "Within the first condition, we have to carefully ***justify why the prediction using regression is valid and accurate***.\n",
    "\n",
    "Within the second condition, we have to ***explain where this causal relationship comes from***.\n",
    "\n",
    "There are lots of types of regression in the machine learning:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Linear Regression\n",
    "As we mentioned before, the relationship within the linear regression model is strictly linear."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Logistic Regression\n",
    "The logistic regression use the sigmoid function $f(x)=\\frac{1}{1+e^{-x}}$ to output a value between 0~1.\n",
    "\n",
    "This regression model could be used to solve classification problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 Polynomial Regression\n",
    "The polynomial regression model could learn a non-linear relationship $y=a_0+a_1x+a_2x^2...$\n",
    "\n",
    "From the above equation we could see that, ***the original feature is transformed to polynomial features of given degrees and then the final relationship is modeled as a linear model.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4 Support Vector Regression (SVR)\n",
    "This is very similar to the Support Vector Machine (which we covered in the classification tutorial) and slight modified to solve regression problems.\n",
    "\n",
    "The core goal of SVR is that we want to have the maximum number of data points between the boundary lines and the best-fit line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5 Decision Tree Regression\n",
    "This regression model use a tree-like structure to solve the problem.\n",
    "\n",
    "Basically you will meet lots of \"test\" stored in the roots. You could choose branches based on the answer for each \"test\" and reach the leaf node which embeds the final answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.6 Ridge Regression (L2 Regularisation)\n",
    "This is the more powerful and robust version of linear regression by adding the L2 regularisation term. We will return to this later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.7 Lasso Regression (L1 Regularisation)\n",
    "This is similar to the ridge regression but using L1 regularisation term instead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. What is Supervised Learning?\n",
    "Supervised Learning is the machine learning task to learn a mapping between the input features and the output and the goal is to ***generalise from the training data to accurately find the result for unseen data***.\n",
    "\n",
    "Here, we will start with the linear regression to help you understand more about the supervised learning and feel the power of regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Loss Function\n",
    "Loss is defined as the difference between the predicted result and the true value, which could be used to measure the distance between points in the feature spaces.\n",
    "\n",
    "A valid loss function must obey the following rules:\n",
    "\n",
    "1. The result is non-negative.\n",
    "\n",
    "2. The loss/distance is symmetric: $Loss(A, B)=Loss(B, A)$\n",
    "\n",
    "3. Triangular Inequality: $Loss(A,C) \\leqslant Loss(A,B)+Loss(B,C)$ for any possible A, B, C\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.1.1 Mean Squared Error (MSE)\n",
    "MSE is a very commonly used loss function within the regression problem as it suits problems with continuous variables very much.\n",
    "\n",
    "The MSE could expressed as: $MSE(y,\\hat{y})=\\frac{1}{N}\\sum_{i=1}^{N} (y_i-\\hat{y_i})^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(prediction, target):\n",
    "    '''\n",
    "        Return the MSE between the prediction and the target.\n",
    "\n",
    "    Argument:\n",
    "        \n",
    "    '''"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "88279d2366fe020547cde40dd65aa0e3aa662a6ec1f3ca12d88834876c85e1a6"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
